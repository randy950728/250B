{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pickle\n",
    "import operator\n",
    "import numpy as np\n",
    "from nltk.corpus           import brown, stopwords\n",
    "from sklearn.cluster       import KMeans\n",
    "from sklearn.neighbors     import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Data prepping\n",
    "# data_file \t\t  = open(\"striped_words.pickle\",'w')\n",
    "# striped_brwn \t  = [word.lower().strip(string.punctuation) for word in brown.words()]\n",
    "# striped_stop_brwn = [word for word in striped_brwn if not(word in stopwords.words('english'))]\n",
    "\n",
    "\n",
    "# pickle.dump(striped_stop_brwn,data_file)\n",
    "# data_file.close()\n",
    "# print(len(striped_brwn))\n",
    "# print(len(striped_stop_brwn))\n",
    "\n",
    "# Data Reading\n",
    "data_file = open(\"striped_words.pickle\",'r')\n",
    "words \t  = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = dict()\n",
    "for word in words:\n",
    "\tif not(word in word_count):\n",
    "\t\tword_count[word]=1\n",
    "\telse:\n",
    "\t\tword_count[word]+=1\n",
    "\n",
    "sorted_word_count = sorted(word_count.items(), key=operator.itemgetter(1))\n",
    "sorted_word_count.reverse()\n",
    "sorted_word_count = sorted_word_count[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_words = sorted_word_count[0:5000]\n",
    "one_words  = sorted_word_count[0:1000]\n",
    "all_five_words = [datum[0] for datum in five_words]\n",
    "all_one_words  = [datum[0] for datum in one_words]\n",
    "joint_one_words= zip(all_one_words,[0.0]*len(all_one_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwc \t= np.zeros((5000,1000))\n",
    "pc_dict = dict(joint_one_words)\n",
    "# for word in all_five_words:\n",
    "# \tnwc[word] = dict(joint_one_words)\n",
    "\n",
    "\n",
    "for i in range(len(words)):          # Iterate through all text\n",
    "    if(words[i] in all_five_words):  # If word within the top 5000 words\n",
    "        parent_idx = all_five_words.index(words[i])\n",
    "        # Iterate though w1, w2, w3, w4\n",
    "        # w1\n",
    "        # print(words[i-1])\n",
    "        if((i-1)>=0 and words[i-1] in all_one_words):\n",
    "            child_idx = all_one_words.index(words[i-1])\n",
    "            nwc[parent_idx,child_idx]+=1\n",
    "\n",
    "        # w2\n",
    "        if((i-2)>=0 and words[i-2] in all_one_words):\n",
    "            child_idx = all_one_words.index(words[i-2])\n",
    "            nwc[parent_idx,child_idx]+=1\n",
    "\n",
    "        # w3\n",
    "        if((i+1)<len(one_words) and words[i+1] in all_one_words):\n",
    "            child_idx = all_one_words.index(words[i+1])\n",
    "            nwc[parent_idx,child_idx]+=1\n",
    "\n",
    "        # w4\n",
    "        if((i+2)<len(one_words) and words[i+2] in all_one_words):\n",
    "            child_idx = all_one_words.index(words[i+2])\n",
    "            nwc[parent_idx,child_idx]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwc=np.copy(nwc)\n",
    "for i in range(len(all_five_words)):\n",
    "    total = sum(pwc[i,:])\n",
    "    if(total ==0):\n",
    "        continue\n",
    "    pwc[i,:]=pwc[i,:]/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_c = sum([datum[1] for datum in one_words])\n",
    "pc = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    pc[i] = one_words[i][1]/float(total_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in pc:\n",
    "    if(data==0):\n",
    "        print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'one', u'would', u'said', u'new', u'could', u'time', u'two', u'may', u'first', u'like', u'man', u'even', u'made', u'also', u'many', u'must', u'af', u'back', u'years', u'much', u'way', u'well', u'people', u'mr', u'little', u'state', u'good', u'make', u'world', u'still', u'see', u'men', u'work', u'long', u'get', u'life', u'never', u'day', u'another', u'know', u'last', u'us', u'might', u'great', u'old', u'year', u'come', u'since', u'go', u'came', u'right', u'states', u'used', u'three', u'take', u'house', u'use', u'without', u'place', u'american', u'around', u'however', u'home', u'1', u'small', u'found', u'mrs', u'thought', u'went', u'say', u'part', u'general', u'high', u'upon', u'school', u'every', u'united', u'got', u'left', u'number', u'course', u'2', u'war', u'always', u'away', u'something', u'fact', u'water', u'though', u'public', u'less', u'put', u'think', u'almost', u'hand', u'enough', u'far', u'took', u'head', u'yet', u'government', u'system', u'better', u'set', u'told', u'nothing', u'night', u'end', u'called', u'eyes', u'find', u'going', u'look', u'asked', u'later', u'knew', u'point', u'program', u'next', u'business', u'city', u'group', u'give', u'days', u'toward', u'young', u'let', u'room', u'president', u'side', u'social', u'present', u'given', u'several', u'order', u'second', u'national', u'possible', u'rather', u'face', u'per', u'form', u'among', u'often', u'important', u'things', u'looked', u'early', u'white', u'case', u'john', u'large', u'big', u'need', u'four', u'within', u'become', u'felt', u'children', u'along', u'saw', u'best', u'church', u'ever', u'least', u'power', u'development', u'light', u'thing', u'seemed', u'family', u'interest', u'want', u'members', u'others', u'mind', u'area', u'country', u'although', u'turned', u'done', u'open', u'god', u'service', u'certain', u'kind', u'problem', u'different', u'began', u'thus', u'door', u'help', u'sense', u'means', u'whole', u'matter', u'perhaps', u'york', u'times', u'human', u'law', u'line', u'3', u'name', u'example', u'action', u'company', u'hands', u'show', u'local', u'five', u'whether', u'history', u'gave', u'either', u'today', u'act', u'feet', u'across', u'quite', u'taken', u'past', u'anything', u'seen', u'death', u'body', u'experience', u'really', u'half', u'week', u'words', u'word', u'car', u'field', u'already', u'information', u\"i'm\", u'shall', u'tell', u'college', u'together', u'money', u'period', u'held', u'keep', u'sure', u'probably', u'free', u'seems', u'miss', u'political', u'cannot', u'behind', u'real', u'air', u'question', u'office', u'making', u'brought', u'whose', u'special', u'major', u'problems', u'heard', u'became', u'ago', u'federal', u'moment', u'study', u'known', u'available', u'result', u'street', u'economic', u'boy', u'position', u'reason', u'south', u'change', u'board', u'individual', u'job', u'society', u'areas', u'west', u'close', u'turn', u'true', u'community', u'love', u'force', u'court', u'full', u'seem', u'cost', u'wife', u'age', u'future', u'wanted', u'voice', u'department', u'woman', u'center', u'control', u'common', u'policy', u'necessary', u'front', u'sometimes', u'following', u'girl', u'six', u'c', u'clear', u'land', u'students', u'able', u'feel', u'mother', u'party', u'provide', u'music', u'4', u'education', u'university', u'effect', u'child', u'level', u'town', u'stood', u'run', u'military', u'short', u'morning', u'total', u'outside', u'rate', u'figure', u'art', u'class', u'century', u'north', u'washington', u'usually', u'leave', u'plan', u'therefore', u'top', u'evidence', u'million', u'sound', u'black', u'hard', u'strong', u'tax', u'various', u'says', u'believe', u'value', u'type', u'play', u'surface', u'mean', u'soon', u'table', u'lines', u'modern', u'near', u'peace', u'book', u'road', u'red', u'minutes', u'personal', u'process', u'situation', u'english', u'women', u'alone', u'increase', u'schools', u'idea', u'gone', u'living', u'started', u'months', u'america', u'longer', u'dr', u'cut', u'finally', u'private', u'third', u'secretary', u'nature', u'section', u'greater', u'call', u'expected', u\"that's\", u'fire', u'needed', u'view', u'kept', u'values', u'ground', u'everything', u'dark', u'pressure', u'space', u'basis', u'east', u'father', u'complete', u'b', u'required', u'spirit', u'union', u\"i'll\", u'except', u'moved', u'wrote', u'return', u'conditions', u'support', u'particular', u'attention', u'late', u'recent', u'nations', u'live', u'hope', u'brown', u'else', u'costs', u'beyond', u'forces', u'taking', u'stage', u'hours', u'dead', u'material', u'report', u'low', u'inside', u'read', u'person', u'coming', u'instead', u'heart', u'looking', u'data', u'miles', u'lost', u'pay', u'added', u'amount', u'1960', u'single', u'makes', u'followed', u'feeling', u'simply', u'move', u'cold', u'industry', u'basic', u'including', u'hundred', u'research', u'tried', u'10', u'developed', u'hold', u'reached', u\"can't\", u'committee', u'island', u'defense', u'equipment', u'actually', u'shown', u'river', u'son', u'central', u'religious', u'getting', u'st', u'sort', u'ten', u'beginning', u'received', u'friends', u'terms', u'rest', u'trying', u'especially', u'care', u'medical', u'u.s', u'indeed', u'picture', u'administration', u'fine', u'subject', u'difficult', u'higher', u'building', u'simple', u'wall', u'meeting', u'walked', u'floor', u'bring', u'foreign', u'passed', u'5', u'range', u'similar', u'paper', u'final', u'training', u'property', u'natural', u'market', u'growth', u'county', u'congress', u'police', u'international', u'cent', u'england', u'talk', u'written', u'start', u'suddenly', u'hear', u'story', u'answer', u'issue', u'hall', u'needs', u'considered', u'countries', u'likely', u'working', u'earth', u'sat', u'labor', u'happened', u'purpose', u'results', u'entire', u'meet', u'william', u'stand', u'difference', u'cases', u'hair', u'production', u'stock', u'involved', u'fall', u'food', u'particularly', u'increased', u'boys', u'earlier', u'thinking', u'club', u'using', u'paid', u'effort', u'sent', u'letter', u'knowledge', u'hour', u'girls', u'christian', u'yes', u'industrial', u'trade', u'ideas', u'weeks', u'ready', u'certainly', u'square', u'bill', u'points', u'blue', u'deal', u'bad', u'moral', u'method', u'due', u'addition', u'methods', u'statement', u'nearly', u'decided', u'directly', u'showed', u'throughout', u'reading', u'neither', u'kennedy', u'anyone', u'color', u'according', u'try', u'questions', u'french', u'lay', u'nation', u'services', u'programs', u'size', u'remember', u'physical', u'member', u'southern', u'record', u'western', u'understand', u'comes', u'strength', u'normal', u'population', u'concerned', u'district', u'temperature', u'appeared', u'p', u'volume', u'merely', u'ran', u'trouble', u'summer', u'aid', u'trial', u'direction', u'1961', u'continued', u'literature', u'maybe', u'sales', u'friend', u'list', u'evening', u'generally', u'army', u'association', u'provided', u'led', u'influence', u'met', u'changes', u'chance', u'student', u'step', u'husband', u'opened', u'science', u'former', u'hot', u'average', u'series', u'works', u'cause', u'month', u'lead', u'george', u'piece', u'soviet', u'stopped', u'planning', u'theory', u'effective', u'direct', u'systems', u'wrong', u'ways', u'organization', u'movement', u'freedom', u'worked', u'ask', u'clearly', u'efforts', u'somewhat', u'consider', u'note', u'lot', u'forms', u'spring', u'bed', u'treatment', u'beautiful', u'press', u'fear', u'meaning', u'j', u'hotel', u'truth', u'e', u'placed', u\"i've\", u'wide', u\"he's\", u'plant', u\"man's\", u'apparently', u'respect', u'groups', u'carried', u'degree', u'numbers', u'reaction', u'easy', u'15', u'manner', u'farm', u'running', u'approach', u'30', u'immediately', u'game', u'lower', u'recently', u'larger', u'daily', u'feed', u'charge', u'eye', u'oh', u'middle', u'de', u'performance', u'couple', u'arms', u'persons', u'opportunity', u'understanding', u'blood', u'march', u'progress', u'radio', u'fiscal', u'technical', u'stop', u'described', u'6', u'additional', u'chief', u'main', u'religion', u'reported', u'served', u'based', u'window', u'determined', u'image', u'steps', u'decision', u'test', u'europe', u'responsibility', u'character', u'british', u'aj', u'gun', u'writing', u'account', u'appear', u'horse', u'learned', u'ones', u'serious', u'corner', u'types', u'activity', u'green', u'length', u'activities', u'slowly', u'returned', u'specific', u'forward', u'audience', u'lived', u'obtained', u'letters', u'nuclear', u'moving', u'hit', u'quality', u'plane', u'gives', u'latter', u'straight', u'design', u'doubt', u'seven', u'obviously', u'justice', u'plans', u'parts', u'pattern', u'staff', u'shot', u'function', u'figures', u'include', u'stay', u'poor', u'born', u'operation', u'choice', u'saying', u'whatever', u'cars', u'sun', u'faith', u'pool', u'waiting', u'lack', u'speak', u'8', u'completely', u'standard', u'mass', u'wish', u'ball', u'hospital', u'heavy', u'corps', u'extent', u'democratic', u'deep', u'principle', u'income', u'language', u\"there's\", u'ahead', u'firm', u'visit', u'analysis', u'importance', u'expect', u'distance', u'price', u'none', u'designed', u'growing', u'products', u'established', u'indicated', u'effects', u'determine', u'negro', u'easily', u'elements', u'cities', u'stress', u'12', u'division', u'continue', u'attitude', u'serve', u'leaders', u'existence', u'pretty', u'closed', u'factors', u'remained', u'write', u'limited', u'applied', u'hardly', u'thomas', u'agreement', u'afternoon', u'scene', u'reach', u'season', u'married', u'rhode', u'drive', u'health', u'attack', u'interested', u'suggested', u'station', u'professional', u'covered', u'becomes', u'played', u'eight', u'spent', u'current', u\"i'd\", u'despite', u'role', u'built', u'exactly', u'commission', u'unit', u'20', u'council', u'teeth', u'studies', u'race', u'reasons', u'charles', u'original', u'date', u'machine', u'mouth', u'rise', u'rates', u'relations', u'james', u'related', u'prepared', u'1959', u'supply', u'trees', u'demand', u'news', u'unless', u'bit', u'dropped', u'officer', u'playing', u'raised', u'events', u'sunday', u'standing', u'director', u'doctor', u'walk', u'facilities', u'energy', u'meant', u'r', u'talking', u'sides', u'clay', u'7', u'places', u'june', u'poet', u'glass', u'knows', u'actual', u'gas', u'filled', u'jazz', u'techniques', u\"he'd\", u'chicago', u'share', u'claim', u'entered', u'style', u'materials', u'caught', u'institutions', u'concern', u'fight', u'happy', u'dollars', u'bridge', u'popular', u'christ', u'suppose', u'100', u'cattle', u'radiation', u'follow', u'included', u'heat', u'thousand', u'status', u'communist', u'parents', u'behavior', u'opinion', u'accepted', u'film', u'usual', u'giving', u'churches', u'conference', u'primary', u'sitting', u'books', u'considerable', u'funds', u'changed']\n"
     ]
    }
   ],
   "source": [
    "sigma_w=np.zeros((5000,1000))\n",
    "for i in range(5000):\n",
    "    for j in range(1000):\n",
    "        if(pwc[i,j]/pc[j]>0 and np.log(pwc[i,j]/pc[j])>0):  \n",
    "            sigma_w[i,j]=np.log(pwc[i,j]/pc[j])\n",
    "print(all_one_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_words = ['communism', 'autumn', 'cigarette', 'pulmonary', 'mankind','africa',\n",
    "              'chicago', 'revolution','september','chemical','detergent','dictionary',\n",
    "              'storm', 'worship']\n",
    "def cos_sim(x, y, fet_len, embed):\n",
    "    numer= np.dot(embed[x[0],x[2]],embed[y[0],y[1]])\n",
    "    denom= np.linalg.norm(embed[x[0],x[2]])*np.linalg.norm(embed[x[0],x[2]])\n",
    "    return(1-(numer/denom))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(sigma_w)\n",
    "reduced_sigma_w = pca.fit_transform(sigma_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('communism', u'utopian', u'utopian')\n",
      "('autumn', u'whip', u'summer')\n",
      "('cigarette', u'andy', u'andy')\n",
      "('pulmonary', u'artery', u'artery')\n",
      "('mankind', u'christ', u'christ')\n",
      "('africa', u'asia', u'germany')\n",
      "('chicago', u'washington', u'board')\n",
      "('revolution', u'violent', u'civil')\n",
      "('september', u'december', u'november')\n",
      "('chemical', u'kind', u'characteristics')\n",
      "('detergent', u'liquid', u'foam')\n",
      "('dictionary', u'text', u'stored')\n",
      "('storm', u'saturday', u'saturday')\n",
      "('worship', u'prize', u'shared')\n"
     ]
    }
   ],
   "source": [
    "nearest_mod         = NearestNeighbors(n_neighbors=2, algorithm='auto', metric=\"cosine\").fit(sigma_w)\n",
    "reduced_nearest_mod = NearestNeighbors(n_neighbors=2, algorithm='auto', metric=\"cosine\").fit(reduced_sigma_w)\n",
    "for word in test_words:\n",
    "    idx = all_five_words.index(word)\n",
    "    dist_a, nrst_idx_a = nearest_mod.kneighbors(sigma_w[idx,:].reshape((1,1000)))\n",
    "    dist_b, nrst_idx_b = reduced_nearest_mod.kneighbors(reduced_sigma_w[idx,:].reshape((1,100)))\n",
    "    print(word, all_five_words[nrst_idx_a[0,1]], all_five_words[nrst_idx_b[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          1.04244578 ...,  0.          2.55611225  0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.23386624  0.         ...,  0.          0.          0.        ]\n",
      " [ 1.26522855  1.17213588  0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "cluster_a = KMeans(n_clusters=100, random_state=0, precompute_distances=True).fit(sigma_w)\n",
    "cluster_b = KMeans(n_clusters=100, random_state=0, precompute_distances=True).fit(reduced_sigma_w)\n",
    "print(cluster_a.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attacks       \tgrabbed\n",
      "island       \twarmth\n",
      "owen       \tthree\n",
      "system       \tanode\n",
      "travel       \tdata\n",
      "companies       \ttest\n",
      "truly       \tloud\n",
      "charged       \thouse\n",
      "must       \treview\n",
      "logical       \tinformation\n",
      "passages       \tstruggle\n",
      "skirt       \ttax\n",
      "reading       \tmiles\n",
      "medical       \ttraining\n",
      "find       \ttimes\n",
      "podger       \tdistinct\n",
      "world       \tcould\n",
      "dictionary       \t2\n",
      "point       \tf\n",
      "railroad       \tjesus\n",
      "per       \thouse\n",
      "completion       \tsee\n",
      "acceptance       \tcent\n",
      "study       \trealism\n",
      "what's       \taround\n",
      "new       \tdominant\n",
      "sake       \tcar\n",
      "11       \thighly\n",
      "local       \tservant\n",
      "around       \ttoward\n",
      "problem       \teffects\n",
      "research       \tjune\n",
      "distinguish       \tcope\n",
      "market       \texperience\n",
      "became       \ttoward\n",
      "types       \taccount\n",
      "stomach       \teast\n",
      "equipment       \tmillion\n",
      "education       \tsocial\n",
      "values       \thigh\n",
      "affairs       \tinterest\n",
      "tax       \tlaw\n",
      "new       \tappeal\n",
      "1960       \tdays\n",
      "parties       \trussians\n",
      "medical       \twell\n",
      "beef       \tmany\n",
      "question       \tsecretary\n",
      "blues       \tone\n",
      "diffusion       \tassociation\n"
     ]
    }
   ],
   "source": [
    "centroid_a = cluster_a.cluster_centers_\n",
    "centroid_b = cluster_b.cluster_centers_\n",
    "for i in range(0,100,2):\n",
    "    dist_a, nrst_idx_a = nearest_mod.kneighbors(centroid_a[i,:].reshape((1,1000)))\n",
    "    dist_a, nrst_idx_b = nearest_mod.kneighbors(centroid_a[i+1,:].reshape((1,1000)))\n",
    "    print(all_five_words[nrst_idx_a[0,1]]+\"       \\t\"+all_five_words[nrst_idx_b[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoulders       \tcouple\n",
      "protein       \tdiscrimination\n",
      "surface       \treceived\n",
      "simply       \texcitement\n",
      "decision       \tgo\n",
      "computed       \tfeb\n",
      "stuck       \tmiles\n",
      "canada       \t1950\n",
      "immortality       \texperience\n",
      "court       \tpossible\n",
      "value       \tplaces\n",
      "yeah       \tvacuum\n",
      "yankees       \t15\n",
      "hoag       \ttook\n",
      "edition       \tambassador\n",
      "costs       \taround\n",
      "education       \tmeaningful\n",
      "much       \tevident\n",
      "4       \teven\n",
      "version       \tenforced\n",
      "amen       \tnature\n",
      "i.e       \tcommittee\n",
      "building       \tcarolina\n",
      "institutions       \tprotection\n",
      "pleasure       \tnovember\n",
      "tell       \tdue\n",
      "lb       \the's\n",
      "situations       \tsad\n",
      "effect       \tcompanies\n",
      "techniques       \tjazz\n",
      "per       \tcost\n",
      "development       \ttake\n",
      "production       \tmistake\n",
      "dark       \trequire\n",
      "state       \tscene\n",
      "front       \tareas\n",
      "f       \ttimes\n",
      "america       \tpurposes\n",
      "porch       \tfather\n",
      "calif       \tgirl\n",
      "program       \tevidence\n",
      "plug       \tissued\n",
      "face       \talert\n",
      "donald       \t1961\n",
      "policy       \ttwo\n",
      "side       \tdistinguish\n",
      "days       \thair\n",
      "boots       \tfamily\n",
      "cold       \tforms\n",
      "wear       \ttake\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100,2):\n",
    "    dist_a, nrst_idx_a = reduced_nearest_mod.kneighbors(centroid_b[i,:].reshape((1,100)))\n",
    "    dist_a, nrst_idx_b = reduced_nearest_mod.kneighbors(centroid_b[i+1,:].reshape((1,100)))\n",
    "    print(all_five_words[nrst_idx_a[0,1]]+\"       \\t\"+all_five_words[nrst_idx_b[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2    1    2    1    1   29    3   10    4    4    1   14    1   57   97\n",
      "    1  254    4    4    1    1    3    1    1   78    3    1    9  433  115\n",
      "  165    8    1  244   22    5    1   11    5    1    1    1    1   50    1\n",
      "   50    1    1    1  433    1    1    1    1    9   16    1    1   58    1\n",
      "    1    1    1    1  123    1   72    1   47    1   32    1    1  116    1\n",
      "    2   72  174    1    1    1  147    1    1    1    1    1   10    1    1\n",
      "    1    1    9 1897    1    1   43    1    1    1]\n",
      "[ 21  16  73  76   8  61  16  96  64  20  65  85  86  11  89  92  87  59\n",
      "  35  16  52   6 266 120  49  25 117  39 101  90  28  16  65 102  56  48\n",
      "   8 110  43  81  91   3  85  15   5  70  43  55  51  29  49  50  67  75\n",
      "   1  40  34  59  29  22  14   2  12  18  24 121  18  36  19  51  35   3\n",
      "  12  92  31  66  75  12  96  29   5   2 143 102   2  70 101   6  12  26\n",
      "  22  39  20  58  82  12  30   6  78  47]\n"
     ]
    }
   ],
   "source": [
    "cluster_a_size = np.zeros(100,dtype='int32')\n",
    "cluster_b_size = np.zeros(100,dtype='int32')\n",
    "for i in range(5000):\n",
    "    idx_a = cluster_a.predict(sigma_w[i,:].reshape((1,1000)))\n",
    "    idx_b = cluster_b.predict(reduced_sigma_w[i,:].reshape((1,100)))\n",
    "    cluster_a_size[idx_a]+=1\n",
    "    cluster_b_size[idx_b]+=1\n",
    "print(cluster_a_size)\n",
    "print(cluster_b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_a_size = cluster_a_size.argsort()\n",
    "sorted_b_size = cluster_b_size.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obviously\n",
      "railroad\n",
      "questionnaire\n",
      "reorganization\n",
      "merger\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    idx_a = cluster_a.predict(sigma_w[i,:].reshape((1,1000)) )\n",
    "#     idx_b = cluster_b.predict(reduced_sigma_w[i,:].reshape((1,100)))\n",
    "    if(idx_a==sorted_a_size[65]):\n",
    "        print(all_five_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "city\n",
      "group\n",
      "church\n",
      "family\n",
      "body\n",
      "society\n",
      "community\n",
      "party\n",
      "county\n",
      "nation\n",
      "population\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "#     idx_a = cluster_a.predict(sigma_w[i,:].reshape((1,1000)) )\n",
    "    idx_b = cluster_b.predict(reduced_sigma_w[i,:].reshape((1,100)))\n",
    "    if(idx_b==sorted_b_size[14]):\n",
    "        print(all_five_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
